---
project_title: Interaction in VR
project_description: In my bachelor thesis and a follow-up paper, I explored eye-tracking and gesture interaction in VR.
project_image: thesis.jpg
project_image_small: thesis.jpg
project_image_alt_text: A VR scene with two hands manipulating a distant cube.
slug: thesis
---


::: article
::: paragraph
::: image
::: video
<iframe src="https://www.youtube.com/embed/NzLrZSF8aDM" title="YouTube video of the Gaze+Pinch technique." frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
:::
:::

::: text
## Gaze + Pinch in Action

&nbsp;

The accommodating paper co-written with [Ken Pfeuffer](https://kenpfeuffer.com/) was published to the [ACM Digital Library](https://dl.acm.org/citation.cfm?id=3132180) for [the 5th ACM Symposium on Spatial User Interaction (SUI 2017)](http://www.sui2017.org/).  

&nbsp; 

You can find more publications of mine on [Google Scholar](https://scholar.google.de/citations?user=ZHmZq24AAAAJ&hl=en). There is also a [full talk about the Gaze+Pinch paper](https://www.youtube.com/watch?v=YdKT42tZdQE) given by my colleague Ken Pfeuffer at SUI 2017.
:::
:::
::: paragraph
::: text
## Eye-Tracking and Gestures in VR

&nbsp;

In my bachelor thesis we proposed a new interaction technique integrating manual interaction and eye-tracking into VR, called gaze + pinch.  

&nbsp; 

Non-VR 3D interaction techniques have had many recent approaches using manual and gaze-based input which we propose could improve interaction in VR as well.  

&nbsp; 

Manual input appears particularly promising to solve problems of intuitiveness and immersion but lacks the ability to easily interact with remote objects, which eye-tracking tries to deal with.
::: 

::: image
![Basic 3D interaction with gaze + pinch to manipulate cubes in a VR setting.](../static/img/$project_image$) \

::: caption
Basic 3D interaction with gaze + pinch.
::: 
:::
:::

::: paragraph

::: image
![HTC Vive headset and controllers. Image from ETC-USC on flickr https://www.flickr.com/photos/92587836@N04/24177102722/](../static/img/vive_controllers.jpg) \

::: caption
HTC Vive headset and controllers. Image from [ETC-USC on flickr](https://www.flickr.com/photos/92587836@N04/24177102722/).
:::
:::

::: text
## Immersive and Intuitive Interaction

&nbsp;

The current state of the art in VR interaction is controllers like the ones of the HTC Vive shown here.
But introducing foreign objects into a VR scene can break immersion, the most important property of any VR application.  

&nbsp; 

This is especially true for applications where the user wouldn't expect to hold something in their hands, like a social or climbing application.
:::
:::

::: paragraph
::: text
## Expanding the Concept

&nbsp;

Thus, we introduced a new concept combining the advantages of gesture interaction with those of eye tracking.  

&nbsp; 

One example application we built is a  living room scene, in which the user can use gaze + pinch to arrange their furniture to their liking.  

&nbsp; 

In this scene, we demonstrate how one can easily use eye gaze for selection (indicated by the grey circle) in combination with gesture interaction for positioning.
::: 

::: image
![A 3D living room scene, showing eye gaze + hand pinching interaction in VR. The image shows a picture-in-picture view of the user in the top right.](../static/img/paper_livingroom.jpg) \

::: caption
In a 3D living room scene, the user can rearrange their furniture by using gaze + pinch.
::: 
:::
:::

:::